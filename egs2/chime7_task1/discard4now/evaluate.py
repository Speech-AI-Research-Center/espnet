"""
import argparse
import json
from lhotse.recipes.chime6 import TimeFormatConverter
from pyannote.metrics.diarization import JaccardErrorRate, DiarizationErrorRate
import glob
import os
from pathlib import Path
import jiwer # we use jiwer to find the best permutation then call score.sh instead
import warnings
import pandas as pd
import logging

parser = argparse.ArgumentParser("Python-based evaluation script for CHiME-7 Task 1 Challenge")
parser.add_argument("--sys_json_dir", help="Path to folder containing system-produced JSON annotation. "
                                           "It is supposed to have 3 sub-folders: chime6, dipco and mixer6, "
                                           "each containing JSON files for all sessions. "
                                           "If only one of these sub-folders is provided (e.g. only chime6) "
                                           "only that one will be evaluated but a warning will be raised."
                                           , required=True, type=str)
parser.add_argument("--ref_json_dir", help="Path to folder containing system JSON annotation. "
                                           "Basically it is the $CHIME7Task1_DIR/transcription_scoring folder as generated by the create_dataset.sh script."
                                           "It should have 3 sub-folders: chime6, dipco and mixer6. Each "
                                           "dataset sub-folder contains JSON files for each session.", required=True, type=str)
parser.add_argument("--log_dir", help="Path to where we should ", required=True, type=str)
parser.add_argument("--track", default=1, help="Choose between 1,2,3. "
                                               "1: main track, will compute DER, JER, SA-WER for each dataset () and  "
                                               "", type=int)
parser.add_argument("--collar", default=0.5, help="See "
                                                  "https://github.com/pyannote/pyannote-metrics/issues/63",
                    type=float)

def evaluate_der(submission_jsons, ref_jsons):
    # check if they are same length and have same names

    if not (len(submission_jsons) == len(ref_jsons)):
        if len(ref_jsons) < len(submission_jsons):
            raise RuntimeError("For some reason the number of reference JSONs for each session in {} is "
                               "less than the system ones in {}, did you delete some by error ? In that case "
                               "you need to regenerate the data using create_dataset.sh. "
                               "You have {} reference JSONs in {} versus {} system JSONs in {}".format())
        warnings.warn("It seems that your {} has less "

    #set([])

    # prepare annotation for DER and JER calculation via pyannote

#TODO must discard for CHiME6 the beginning !

def evaluate_wer(sa_wer=False):
    if sa_wer:
        pass
        # evaluate first diarization
    else:
        pass
        # we simply cat the hypothesis for each speaker and then compute WER across whole recording



if __name__ == "__main__":
    args = parser.parse_args()
    # find if user has correct subfolders for each dataset, mixer6, dipco and chime6

    for dset in ["chime6", "dipco", "mixer6"]:
        assert os.path.exists(os.path.join(args.ref_json_dir, dset)), "Did you set --ref_json_dir correctly ?, " \
                                                                        "It should have chime6, dipco and mixer6 subfolders. " \
                                                                        "You should set --ref_json_dir to point to " \
                                                                        "$CHIME7Task1_DIR/transcription_scoring folder as generated by the create_dataset.sh script." \
                                                                        ""
        if not os.path.exists(os.path.join(args.sys_json_dir, dset)):
            warnings.warn("{} does not exists, we will skip evaluation for {} dataset.\n"
                          "NOTE THAT THIS WILL LEAD TO INCORRECT EVALUATION FOR THE SAKE OF THE CHALLENGE.")

    ref_jsons = glob.glob(os.path.join(args.ref_json_dir, "*.json"))
    sys_jsons = glob.glob(os.path.join(args.sys_json_dir, "*.json"))

    if args.track == 1:
        for dset in ["chime6", "dipco", "mixer6"]:
            if not os.path.exists(os.path.join(args.sys_json_dir, dset)):
                continue
            diar_df, asr_df, tot_wer = evaluate_wer(ref_jsons, sys_jsons, sa_wer=True)
            logger.log()

        logger.log()

"""
