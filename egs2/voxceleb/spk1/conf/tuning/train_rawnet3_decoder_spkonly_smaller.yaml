# RawNet3 reproduce recipe configuration.
# Requires approx. 40GRAM per GPU when run with 2GPUs
# or 20GRAM when run with 4GPUs.

# Frontend
frontend: asteroid_frontend
frontend_conf:
    sinc_stride: 16
    sinc_kernel_size: 251
    sinc_filters: 256
    preemph_coef: 0.97
    log_term: 0.000001

# Encoder
encoder: rawnet3
encoder_conf:
  model_scale: 8
  ndim: 1024
  output_size: 1536

# Pooling
pooling: transformer_decoder
pooling_conf:
  vocab_size: 1
  num_blocks: 1
  attention_dim: 256
  attention_heads: 4
  linear_units: 1024
  dropout_rate: 0.1
  positional_dropout_rate: 0.1
  self_attention_dropout_rate: 0.0
  src_attention_dropout_rate: 0.0
  input_layer: "embed"
  pos_enc_class: "pos"
  concat_after: False
  normalize_before: True
  use_output_layer: False

# Projector
projector: rawnet3
projector_conf:
  output_size: 192

# Preprocessor
preprocessor: spk
preprocessor_conf:
  target_duration: 3.0  # seconds
  sample_rate: 16000
  num_eval: 5
  noise_apply_prob: 0.5
  noise_info:
  - [1.0, 'dump/raw/musan_speech.scp', [4, 7], [13, 20]]
  - [1.0, 'dump/raw/musan_noise.scp', [1, 1], [0, 15]]
  - [1.0, 'dump/raw/musan_music.scp', [1, 1], [5, 15]]
  rir_apply_prob: 0.5
  rir_scp: dump/raw/rirs.scp

# Model config
model_conf:
  extract_feats_in_collect_stats: false

# Loss
loss: aamsoftmax
loss_conf:
  margin: 0.3
  scale: 30

# Training related
max_epoch: 160
num_att_plot: 0
num_workers: 8
cudnn_deterministic: False
cudnn_benchmark: True
drop_last_iter: True
iterator_type: category
valid_iterator_type: sequence
shuffle_within_batch: False
log_interval: 100
batch_size: 512
valid_batch_size: 40
grad_clip: 9999
best_model_criterion:
- - valid
  - eer
  - min

# Optimizer
optim: adam
optim_conf:
  lr: 0.001
  weight_decay: 0.00005
  amsgrad: False

# Scheduler
scheduler: CosineAnnealingWarmupRestarts
scheduler_conf:
  first_cycle_steps: 73024
  cycle_mult: 1.0
  max_lr: 0.001
  min_lr: 0.000005
  warmup_steps: 1000
  gamma: 0.7
