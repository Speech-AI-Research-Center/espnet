{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample demo for using ESPnet-Easy!\n",
    "In this notebook, we will train an ASR model on Librispeech-100 dataset. This notebook follows the same dataset preparation process as the kaldi-style dataset. If yo uwant to finetune the pretrained models, please refer to the `libri100_finetune.ipynb` file.\n",
    "\n",
    "This notebook assumes that you have already downloaded the Librispeech-100 dataset from [OpenSLR](https://www.openslr.org/12), and placed the data in `/hdd/dataset/` directory.\n",
    "Please replace the `/hdd/dataset/` directory with your own path."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "This notebook follows an data preparation steps written in `asr.sh`. First, we will create a dump file to store the data id, audio path, and the transcription.\n",
    "\n",
    "ESPnet-Easy accepts several types of datasets, including:\n",
    "- Dictionary-based dataset with the following structure:\n",
    "  ```python\n",
    "  {\n",
    "    \"data_id\": {\n",
    "        \"speech\": path_to_speech_file,\n",
    "        \"text\": transcription\n",
    "    },\n",
    "  }\n",
    "  ```\n",
    "- List of datasets with the following structure:\n",
    "  ```python\n",
    "  [\n",
    "    {\n",
    "        \"speech\": path_to_speech_file,\n",
    "        \"text\": transcription\n",
    "    },\n",
    "  ]\n",
    "  ```\n",
    "\n",
    "If you want to use a dictionary-based dataset, each `data_id` must be unique.\n",
    "ESPnet-Easy also accepts a dump file already created by `asr.sh`. But in this notebook, we will craete dump file from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to install espnet if you don't have it\n",
    "!pwd\n",
    "!pip install -U ../../\n",
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we define a function to create a dataset in dictionary format.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def create_dataset(data_dir):\n",
    "    dataset = {}\n",
    "    for chapter in glob.glob(os.path.join(data_dir, \"*/*\")):\n",
    "        text_file = glob.glob(os.path.join(chapter, \"*.txt\"))[0]\n",
    "\n",
    "        with open(text_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        ids_text = {\n",
    "            line.split(\" \")[0]: line.split(\" \", maxsplit=1)[1].replace(\"\\n\", \"\")\n",
    "            for line in lines\n",
    "        }\n",
    "        audio_files = glob.glob(os.path.join(chapter, \"*.wav\"))\n",
    "        for audio_file in audio_files:\n",
    "            audio_id = os.path.basename(audio_file)[: -len(\".wav\")]\n",
    "            dataset[audio_id] = {\"speech\": audio_file, \"text\": ids_text[audio_id]}\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment out\n",
    "Then, let's create a dump file!\n",
    "\n",
    "Note that the `file` key denotes the file name for the dump file, and the `type` key denotes the type of the inputs.\n",
    "The `type` must be one of the data type listed in the [DATA_TYPES](https://github.com/espnet/espnet/blob/1409d89d1ca33417a7f57e4cfa77925a4f00cc3f/espnet2/train/dataset.py#L208).\n",
    "\n",
    "Then we generate the dump files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's create dump files!  \n",
    "Note that you need to provide a dictionary to indicate dump file for each data.\n",
    "The dictionary should have the following format:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"data_name\": [\"dump_file_name\", \"dump_format\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import espnetez as ez\n",
    "\n",
    "# Then create the dump files\n",
    "DUMP_DIR = \"./dump/libri100\"\n",
    "LIBRI_100_DIRS = [\n",
    "    [\"/hdd/database/librispeech-100/LibriSpeech/train-clean-100\", \"train\"],\n",
    "    [\"/hdd/database/librispeech-100/LibriSpeech/dev-clean\", \"dev-clean\"],\n",
    "    [\"/hdd/database/librispeech-100/LibriSpeech/dev-other\", \"dev-other\"],\n",
    "]\n",
    "data_info = {\n",
    "    \"speech\": [\"wav.scp\", \"sound\"],\n",
    "    \"text\": [\"text\", \"text\"],\n",
    "}\n",
    "\n",
    "for d, n in LIBRI_100_DIRS:\n",
    "    dump_dir = os.path.join(DUMP_DIR, n)\n",
    "    if not os.path.exists(dump_dir):\n",
    "        os.makedirs(dump_dir)\n",
    "\n",
    "    dataset = create_dataset(d)\n",
    "    ez.data.create_dump_file(dump_dir, dataset, data_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dev files, we have `dev-clean` and `dev-other` directories.\n",
    "We can join them to get one dev dataset, by using `ez.data.join_dumps` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ez.data.join_dumps(\n",
    "    [\"./dump/libri100/dev-clean\", \"./dump/libri100/dev-other\"], \"./dump/libri100/dev\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have dataset files in the `dump` directory.\n",
    "It looks like this:\n",
    "\n",
    "wav.scp\n",
    "```\n",
    "1255-138279-0008 /hdd/database/librispeech-100/LibriSpeech/dev-other/1255/138279/1255-138279-0008.flac\n",
    "1255-138279-0022 /hdd/database/librispeech-100/LibriSpeech/dev-other/1255/138279/1255-138279-0022.flac\n",
    "```\n",
    "\n",
    "text\n",
    "```\n",
    "1255-138279-0008 TWO THREE\n",
    "1255-138279-0022 IF I SAID SO OF COURSE I WILL\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train sentencepiece model\n",
    "\n",
    "Next, we will train a sentencepiece model. We need text file for training, so first, let's create a training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training texts from the training data\n",
    "# you can select several datasets to train sentencepiece.\n",
    "ez.preprocess.prepare_sentences([\"dump/libri100/train/text\"], \"dump/spm\")\n",
    "\n",
    "ez.preprocess.train_sentencepiece(\n",
    "    \"dump/spm/train.txt\",\n",
    "    \"data/bpemodel\",\n",
    "    vocab_size=5000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we have finished the data preparation. Now we will configure training process. We can use the configuration files already created by the ESPnet contributers.\n",
    "\n",
    "To use the configuration file, we need to create the yaml file on your local machine. For example, I will use this [e-branchformer config](train_asr_e_branchformer_size256_mlp1024_linear1024_e12_mactrue_edrop0.0_ddrop0.0.yaml).\n",
    "\n",
    "I changed the `batch_bins` parameter from `16000000` to `1600000`, to train on my GPU (RTX2080ti)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing I changed from the original ESPnet in this notebook is the way we define the token list.\n",
    "\n",
    "The original ESPnet configuration defines the token list by giving all tokens in the yaml file, but in the ESPnet-Easy, we just give the path to the vocab file.\n",
    "So the configuration file for preprocessing looks like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "use_preprocessor: true\n",
    "\n",
    "token_type: bpe\n",
    "bpemodel: data/bpemodel/bpe.model\n",
    "rir_scp: null\n",
    "rir_apply_prob: 1.0\n",
    "noise_scp: null\n",
    "noise_apply_prob: 1.0\n",
    "noise_db_range: '13_15'\n",
    "speech_volume_normalize: null\n",
    "non_linguistic_symbols: null\n",
    "\n",
    "cleaner: null\n",
    "g2p: null\n",
    "preprocessor: default\n",
    "preprocessor_conf:\n",
    "  speech_name: speech\n",
    "  text_name: text\n",
    "\n",
    "token_list: data/bpemodel/tokens.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we need to prepare the stats file.\n",
    "We can do this by running the `collect_stats` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import espnetez as ez\n",
    "\n",
    "EXP_DIR = \"exp/train_asr_branchformer_e24_amp\"\n",
    "STATS_DIR = \"exp/stats_all\"\n",
    "training_config = ez.config.from_yaml(\n",
    "    \"asr\",\n",
    "    \"train_asr_e_branchformer_size256_mlp1024_linear1024_e12_mactrue_edrop0.0_ddrop0.0.yaml\",\n",
    ")\n",
    "preprocessor_config = ez.utils.load_yaml(\"preprocess.yaml\")\n",
    "training_config.update(preprocessor_config)\n",
    "\n",
    "# replace token list if required.\n",
    "with open(preprocessor_config[\"token_list\"], \"r\") as f:\n",
    "    training_config[\"token_list\"] = [t.replace(\"\\n\", \"\") for t in f.readlines()]\n",
    "\n",
    "trainer = ez.Trainer(\n",
    "    task='asr',\n",
    "    train_config=training_config,\n",
    "    train_dump_dir=\"dump/libri100/train\",\n",
    "    valid_dump_dir=\"dump/libri100/dev\",\n",
    "    data_info=data_info,\n",
    "    output_dir=EXP_DIR,\n",
    "    stats_dir=STATS_DIR,\n",
    "    ngpu=1,\n",
    ")\n",
    "trainer.collect_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
