{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMPLATE DOCUMENT\n",
    "\n",
    "This is a template document for training ASR models.\n",
    "This document shows the simplest flow of ASR model with `espnetez`.\n",
    "\n",
    "First, we need `espnet` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install espnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import espnetez as ez\n",
    "\n",
    "# We need to create dump file, if we don't use external dataset package.\n",
    "DUMP_DIR = \"./dump/\"\n",
    "\n",
    "# We need to define the data information.\n",
    "data_info = {\n",
    "    \"speech\": [\"wav.scp\", \"sound\"],\n",
    "    \"text\": [\"text\", \"text\"],\n",
    "}\n",
    "ez.data.create_dump_file(DUMP_DIR, your_dataset, data_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train sentencepiece model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ez.preprocess.prepare_sentences([\"dump/train/text\"], \"dump/spm\")\n",
    "ez.preprocess.train_sentencepiece(\n",
    "    \"dump/spm/train.txt\",\n",
    "    \"data/bpemodel\",\n",
    "    vocab_size=5000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ASR model\n",
    "\n",
    "First we need to define the training config, and then run `collect_stats` and `train` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training config\n",
    "EXP_DIR = \"exp/train_asr_branchformer_e24_amp\"\n",
    "STATS_DIR = \"exp/stats\"\n",
    "\n",
    "training_config = ez.config.from_yaml(\n",
    "    \"asr\",\n",
    "    \"config/train_asr_e_branchformer_size256_mlp1024_linear1024_e12_mactrue_edrop0.0_ddrop0.0.yaml\",\n",
    ")\n",
    "preprocessor_config = ez.utils.load_yaml(\"config/preprocess.yaml\")\n",
    "training_config.update(preprocessor_config)\n",
    "\n",
    "with open(preprocessor_config[\"token_list\"], \"r\") as f:\n",
    "    training_config[\"token_list\"] = [t.replace(\"\\n\", \"\") for t in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trainer class\n",
    "trainer = ez.Trainer(\n",
    "    task='asr',\n",
    "    train_config=training_config,\n",
    "    train_dump_dir=\"dump/train\",\n",
    "    valid_dump_dir=\"dump/dev\",\n",
    "    data_info=data_info,\n",
    "    output_dir=EXP_DIR,\n",
    "    stats_dir=STATS_DIR,\n",
    "    ngpu=1,\n",
    ")\n",
    "trainer.collect_stats()\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
